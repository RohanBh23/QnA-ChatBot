{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiZ55hGufEqV"
      },
      "source": [
        "## Loading the Data\n",
        "Unpickling the bAbI Data Set from Meta Research\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U2wPL7TBfEqW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Pwq_vR8ffEqY"
      },
      "outputs": [],
      "source": [
        "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "atWeJKv8fEqY"
      },
      "outputs": [],
      "source": [
        "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6ER6VuIfEqa"
      },
      "source": [
        "## Exploring the Format of the Data\n",
        "\n",
        "The data is in the form - \n",
        "\n",
        "\n",
        "*   Story -> A sequence of simple descriptive sentences.\n",
        "*   Question -> A single question related to the above story.\n",
        "*   Answer -> 'Yes' or 'No'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNE8HWPIfEqb",
        "outputId": "4534b4f9-e148-4ed7-c6fa-98b7384b164c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data type and size :  <class 'list'> 10000\n",
            "Test data type and size :  <class 'list'> 1000\n"
          ]
        }
      ],
      "source": [
        "print('Train data type and size : ', type(train_data),len(train_data))\n",
        "print('Test data type and size : ', type(test_data),len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "mvEZRgeEfEqe",
        "outputId": "cd561f39-5cda-4662-e705-3490615ecd71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sandra got the football there . Mary went to the bedroom . Daniel got the apple there . Sandra travelled to the hallway . Sandra moved to the garden . Mary travelled to the kitchen . Sandra went back to the bedroom . Daniel put down the apple . Sandra put down the football . Sandra journeyed to the office .'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "' '.join(train_data[9][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e8N4vlfBfEqf",
        "outputId": "d77836d9-f63b-45dc-9609-ed92ef97e5f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Is Mary in the kitchen ?'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "' '.join(train_data[9][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9CfVZvyifEqf",
        "outputId": "d45e67d5-c281-4c80-e703-a12469d3ce34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_data[9][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ9yLiqWfEqf"
      },
      "source": [
        "## Setting up Vocabulary of All Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xtaECmgufEqg"
      },
      "outputs": [],
      "source": [
        "vocab = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VYrXOU5dfEqg"
      },
      "outputs": [],
      "source": [
        "all_data = test_data + train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YT4764TwfEqg"
      },
      "outputs": [],
      "source": [
        "for story, question , answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vv-k44fRfEqh"
      },
      "outputs": [],
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdSWU1g-fEqh",
        "outputId": "187f9c94-cdb5-468e-efa9-82975ccd4f5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textfile = open(\"vocab.txt\", \"w\")\n",
        "for element in vocab:\n",
        "    textfile.write(element + \"\\n\")\n",
        "textfile.close()"
      ],
      "metadata": {
        "id": "aoz8ufhZyH4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1HRrPraFfEqi"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ng2eufObfEqi"
      },
      "outputs": [],
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SS4Gna3fEqi",
        "outputId": "2728ddd0-9333-460d-f193-f044de1066a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "max_story_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cp9Nw_OxfEqj"
      },
      "outputs": [],
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWicD-eYfEqj",
        "outputId": "6ef1fbfa-f6c3-4d33-ca6b-6653877dca65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "max_question_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ne41o_fEqj"
      },
      "source": [
        "## Vectorizing the Data\n",
        "\n",
        "\n",
        "*   Padding\n",
        "*   Tokenization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qN9deNFZfEqk"
      },
      "outputs": [],
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dAJYd7ZfEqk"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b3tmXSk6fEqk"
      },
      "outputs": [],
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt18xhbxfEql",
        "outputId": "d8c6b517-c63a-4b7f-dad5-2388b3e42014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 11,\n",
              " '?': 15,\n",
              " 'apple': 19,\n",
              " 'back': 37,\n",
              " 'bathroom': 3,\n",
              " 'bedroom': 22,\n",
              " 'daniel': 13,\n",
              " 'discarded': 25,\n",
              " 'down': 12,\n",
              " 'dropped': 9,\n",
              " 'football': 21,\n",
              " 'garden': 31,\n",
              " 'got': 34,\n",
              " 'grabbed': 4,\n",
              " 'hallway': 5,\n",
              " 'in': 14,\n",
              " 'is': 35,\n",
              " 'john': 33,\n",
              " 'journeyed': 32,\n",
              " 'kitchen': 30,\n",
              " 'left': 10,\n",
              " 'mary': 29,\n",
              " 'milk': 23,\n",
              " 'moved': 6,\n",
              " 'no': 27,\n",
              " 'office': 2,\n",
              " 'picked': 1,\n",
              " 'put': 8,\n",
              " 'sandra': 16,\n",
              " 'the': 26,\n",
              " 'there': 17,\n",
              " 'to': 36,\n",
              " 'took': 18,\n",
              " 'travelled': 24,\n",
              " 'up': 7,\n",
              " 'went': 28,\n",
              " 'yes': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tLOjhJ0rfEql"
      },
      "outputs": [],
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5ATyz8OsfEql"
      },
      "outputs": [],
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzp-9uTgfEql",
        "outputId": "8b8fe7b4-1dfa-4831-f46b-07b0b30bde01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "len(train_story_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BfzeYqNfEqm",
        "outputId": "6598c708-25d8-44c1-82b5-1c1d0cbba272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(train_story_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jcRY0iUofEqm"
      },
      "outputs": [],
      "source": [
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S-Q25UtfEqm"
      },
      "source": [
        "### Complete Function for Vectorization\n",
        "\n",
        "We first loop for every story, query , and answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "\n",
        "Input : \n",
        "\n",
        "*   data: consisting of Stories,Questions,and Answers\n",
        "*   word_index: word index dictionary from tokenizer\n",
        "*   max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "*   max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "Output:\n",
        "    \n",
        "stories,questions, and answers vectorized into padded sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eCv4vRFVfEqm"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "\n",
        "    X = [] # STORIES\n",
        "    Xq = [] # QUESTION\n",
        "    Y = []  # ANSWER\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NG4wVnJAfEqn"
      },
      "outputs": [],
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PWZRWZH0fEqn"
      },
      "outputs": [],
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD446tJgfEqn",
        "outputId": "5d22189b-6428-4640-f444-d62644d28a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 26, 22, 11],\n",
              "       [ 0,  0,  0, ..., 26, 31, 11],\n",
              "       [ 0,  0,  0, ..., 26, 31, 11],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 26, 19, 11],\n",
              "       [ 0,  0,  0, ..., 26, 31, 11],\n",
              "       [ 0,  0,  0, ..., 19, 17, 11]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "inputs_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8RGG_HDfEqn",
        "outputId": "16df6ffe-9155-4ba5-f765-bc564764033c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[35, 33, 14, 26, 30, 15],\n",
              "       [35, 33, 14, 26, 30, 15],\n",
              "       [35, 33, 14, 26, 31, 15],\n",
              "       ...,\n",
              "       [35, 29, 14, 26, 22, 15],\n",
              "       [35, 16, 14, 26, 31, 15],\n",
              "       [35, 29, 14, 26, 31, 15]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "queries_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhEgnC_bfEqo",
        "outputId": "66fb3d32-5bc1-43c0-ed1d-c779bd47cdd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "answers_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0ArMCmQfEqo",
        "outputId": "c642b4c4-de1c-4b96-98e1-79aa16573051"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "sum(answers_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljmVSoAdfEqo",
        "outputId": "90813ae6-b7be-4457-a30d-966ca4bf62c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "tokenizer.word_index['yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-KgnbqCfEqo",
        "outputId": "2482a8cb-fdd7-4ac2-8495-de0c00088c19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "tokenizer.word_index['no']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2PBKj9RfEqo"
      },
      "source": [
        "# **Creating the Model**\n",
        "## Building the Neural Network\n",
        "\n",
        "\n",
        "*   Input Encoder M\n",
        "*   Input Encoder C\n",
        "*   Question Encoder\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YUUcOmLjfEqp"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JUCvKQcfEqp"
      },
      "source": [
        "### Placeholders for Inputs\n",
        "We have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Vam-6QvQfEqp"
      },
      "outputs": [],
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2UyHdrZfEqp"
      },
      "source": [
        "## Encoders\n",
        "\n",
        "### Input Encoder m\n",
        "This encoder will output:\n",
        "(samples, story_maxlen, embedding_dim)\n",
        "\n",
        "The Drop-off layer turns off a percentage of randomly selected Neurons to avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "K7OzLsyCfEqr"
      },
      "outputs": [],
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y7nnqPNfEqs"
      },
      "source": [
        "### Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wJS7AZfNfEqs"
      },
      "outputs": [],
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGRNFJBdfEqs"
      },
      "source": [
        "### Question Encoder\n",
        "\n",
        "To embed the question into a sequence of vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IZSIhJBffEqs"
      },
      "outputs": [],
      "source": [
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWsqmYrzfEqs"
      },
      "source": [
        "### Encode the Sequences\n",
        "\n",
        "Encoded ----> Encoder(Input)\n",
        "\n",
        "\n",
        "Basically encodes input sequence and questions (which are indices) to sequences of dense vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DQTWEwPKfEqt"
      },
      "outputs": [],
      "source": [
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ALrPXe7fEqt"
      },
      "source": [
        "##### Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zz5OQj50fEqt"
      },
      "outputs": [],
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhyNEBpFfEqt"
      },
      "source": [
        "#### Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ly9XqxuYfEqt"
      },
      "outputs": [],
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6fD40VpfEqt"
      },
      "source": [
        "#### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QhDYsKm3fEqu"
      },
      "outputs": [],
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2GPprqyfEqu",
        "outputId": "ed6fe037-b3e1-451e-e3cc-c8951c664aff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wILmFZZXfEqu"
      },
      "outputs": [],
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y2IyWec_fEqu"
      },
      "outputs": [],
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MWqYz9o2fEqu"
      },
      "outputs": [],
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe6pg3VVfEqu",
        "outputId": "2343524d-5c6e-4538-f160-ac317da95b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, None, 64)     2432        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 6, 64)        2432        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L-ejODTfEqv",
        "outputId": "94f6c6f5-cb70-47f9-9a0d-bf4c6b7ba78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 8s 16ms/step - loss: 0.8916 - accuracy: 0.5020 - val_loss: 0.6960 - val_accuracy: 0.4970\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.7021 - accuracy: 0.4944 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6957 - accuracy: 0.4994 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6943 - accuracy: 0.5055 - val_loss: 0.6964 - val_accuracy: 0.5030\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6949 - accuracy: 0.4948 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6944 - accuracy: 0.5023 - val_loss: 0.6933 - val_accuracy: 0.4880\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6942 - accuracy: 0.5058 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6935 - accuracy: 0.5078 - val_loss: 0.6932 - val_accuracy: 0.4800\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6942 - accuracy: 0.5012 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6944 - accuracy: 0.4972 - val_loss: 0.6965 - val_accuracy: 0.4970\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6939 - accuracy: 0.5058 - val_loss: 0.6939 - val_accuracy: 0.4770\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6950 - val_accuracy: 0.4980\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6930 - accuracy: 0.5101 - val_loss: 0.6957 - val_accuracy: 0.4770\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6920 - accuracy: 0.5281 - val_loss: 0.6967 - val_accuracy: 0.5040\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6908 - accuracy: 0.5274 - val_loss: 0.6953 - val_accuracy: 0.4780\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6831 - accuracy: 0.5560 - val_loss: 0.6947 - val_accuracy: 0.5410\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6672 - accuracy: 0.5913 - val_loss: 0.6612 - val_accuracy: 0.6130\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6444 - accuracy: 0.6303 - val_loss: 0.6301 - val_accuracy: 0.6580\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6289 - accuracy: 0.6521 - val_loss: 0.6203 - val_accuracy: 0.6570\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6180 - accuracy: 0.6677 - val_loss: 0.6177 - val_accuracy: 0.6740\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6163 - accuracy: 0.6670 - val_loss: 0.6125 - val_accuracy: 0.6610\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6103 - accuracy: 0.6781 - val_loss: 0.6062 - val_accuracy: 0.6740\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6045 - accuracy: 0.6846 - val_loss: 0.6009 - val_accuracy: 0.6740\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6004 - accuracy: 0.6863 - val_loss: 0.6076 - val_accuracy: 0.6650\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.5909 - accuracy: 0.6930 - val_loss: 0.5976 - val_accuracy: 0.6770\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.5855 - accuracy: 0.6999 - val_loss: 0.5871 - val_accuracy: 0.6840\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5755 - accuracy: 0.7026 - val_loss: 0.5859 - val_accuracy: 0.6850\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.5711 - accuracy: 0.7119 - val_loss: 0.5713 - val_accuracy: 0.6960\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.5598 - accuracy: 0.7182 - val_loss: 0.5603 - val_accuracy: 0.7080\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.5486 - accuracy: 0.7259 - val_loss: 0.5650 - val_accuracy: 0.7100\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5324 - accuracy: 0.7344 - val_loss: 0.5496 - val_accuracy: 0.7160\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.5226 - accuracy: 0.7433 - val_loss: 0.5310 - val_accuracy: 0.7420\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5027 - accuracy: 0.7609 - val_loss: 0.5078 - val_accuracy: 0.7510\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4944 - accuracy: 0.7663 - val_loss: 0.4931 - val_accuracy: 0.7640\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4812 - accuracy: 0.7792 - val_loss: 0.4862 - val_accuracy: 0.7740\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4705 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7750\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4629 - accuracy: 0.7900 - val_loss: 0.5002 - val_accuracy: 0.7630\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4520 - accuracy: 0.7973 - val_loss: 0.4933 - val_accuracy: 0.7790\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4431 - accuracy: 0.8068 - val_loss: 0.4504 - val_accuracy: 0.8000\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.4289 - accuracy: 0.8122 - val_loss: 0.4573 - val_accuracy: 0.8000\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.4231 - accuracy: 0.8152 - val_loss: 0.4422 - val_accuracy: 0.7970\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.4170 - accuracy: 0.8163 - val_loss: 0.4286 - val_accuracy: 0.8220\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.4263 - val_accuracy: 0.8070\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.4025 - accuracy: 0.8262 - val_loss: 0.4048 - val_accuracy: 0.8310\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3991 - accuracy: 0.8306 - val_loss: 0.4162 - val_accuracy: 0.8130\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3786 - accuracy: 0.8385 - val_loss: 0.4266 - val_accuracy: 0.8040\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3925 - accuracy: 0.8322 - val_loss: 0.4065 - val_accuracy: 0.8220\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3767 - accuracy: 0.8372 - val_loss: 0.4154 - val_accuracy: 0.8130\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3759 - accuracy: 0.8384 - val_loss: 0.4077 - val_accuracy: 0.8140\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3679 - accuracy: 0.8421 - val_loss: 0.3959 - val_accuracy: 0.8310\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3660 - accuracy: 0.8435 - val_loss: 0.3907 - val_accuracy: 0.8280\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3644 - accuracy: 0.8469 - val_loss: 0.3912 - val_accuracy: 0.8380\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3531 - accuracy: 0.8515 - val_loss: 0.4239 - val_accuracy: 0.8180\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3553 - accuracy: 0.8498 - val_loss: 0.3933 - val_accuracy: 0.8370\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3519 - accuracy: 0.8498 - val_loss: 0.3877 - val_accuracy: 0.8310\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3505 - accuracy: 0.8523 - val_loss: 0.3936 - val_accuracy: 0.8260\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3485 - accuracy: 0.8558 - val_loss: 0.3861 - val_accuracy: 0.8290\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3440 - accuracy: 0.8525 - val_loss: 0.3813 - val_accuracy: 0.8280\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3423 - accuracy: 0.8553 - val_loss: 0.3983 - val_accuracy: 0.8410\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3424 - accuracy: 0.8538 - val_loss: 0.3900 - val_accuracy: 0.8220\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3277 - accuracy: 0.8605 - val_loss: 0.4027 - val_accuracy: 0.8240\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3301 - accuracy: 0.8610 - val_loss: 0.4037 - val_accuracy: 0.8350\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3287 - accuracy: 0.8623 - val_loss: 0.4031 - val_accuracy: 0.8110\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3290 - accuracy: 0.8601 - val_loss: 0.4186 - val_accuracy: 0.8260\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3252 - accuracy: 0.8612 - val_loss: 0.4232 - val_accuracy: 0.8180\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3207 - accuracy: 0.8627 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3196 - accuracy: 0.8675 - val_loss: 0.4157 - val_accuracy: 0.8250\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3141 - accuracy: 0.8683 - val_loss: 0.4197 - val_accuracy: 0.8260\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3144 - accuracy: 0.8701 - val_loss: 0.3940 - val_accuracy: 0.8330\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3129 - accuracy: 0.8671 - val_loss: 0.4275 - val_accuracy: 0.8240\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3111 - accuracy: 0.8738 - val_loss: 0.4307 - val_accuracy: 0.8120\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3070 - accuracy: 0.8690 - val_loss: 0.4223 - val_accuracy: 0.8170\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3044 - accuracy: 0.8749 - val_loss: 0.4249 - val_accuracy: 0.8210\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3096 - accuracy: 0.8717 - val_loss: 0.4238 - val_accuracy: 0.8200\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3046 - accuracy: 0.8702 - val_loss: 0.4404 - val_accuracy: 0.8190\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3002 - accuracy: 0.8749 - val_loss: 0.4263 - val_accuracy: 0.8220\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2937 - accuracy: 0.8792 - val_loss: 0.4558 - val_accuracy: 0.8160\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2979 - accuracy: 0.8764 - val_loss: 0.4312 - val_accuracy: 0.8200\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2995 - accuracy: 0.8789 - val_loss: 0.4244 - val_accuracy: 0.8190\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2898 - accuracy: 0.8801 - val_loss: 0.4417 - val_accuracy: 0.8300\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2931 - accuracy: 0.8764 - val_loss: 0.4303 - val_accuracy: 0.8270\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2916 - accuracy: 0.8792 - val_loss: 0.4214 - val_accuracy: 0.8240\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2895 - accuracy: 0.8794 - val_loss: 0.4399 - val_accuracy: 0.8260\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2913 - accuracy: 0.8809 - val_loss: 0.4271 - val_accuracy: 0.8270\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2890 - accuracy: 0.8810 - val_loss: 0.4241 - val_accuracy: 0.8230\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2837 - accuracy: 0.8848 - val_loss: 0.4556 - val_accuracy: 0.8190\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2837 - accuracy: 0.8832 - val_loss: 0.4708 - val_accuracy: 0.8180\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2731 - accuracy: 0.8905 - val_loss: 0.4454 - val_accuracy: 0.8260\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2732 - accuracy: 0.8848 - val_loss: 0.4409 - val_accuracy: 0.8280\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2734 - accuracy: 0.8848 - val_loss: 0.4556 - val_accuracy: 0.8220\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2851 - accuracy: 0.8820 - val_loss: 0.4461 - val_accuracy: 0.8150\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2731 - accuracy: 0.8848 - val_loss: 0.4562 - val_accuracy: 0.8130\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2740 - accuracy: 0.8854 - val_loss: 0.4896 - val_accuracy: 0.8190\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2747 - accuracy: 0.8884 - val_loss: 0.4798 - val_accuracy: 0.8060\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2691 - accuracy: 0.8899 - val_loss: 0.4499 - val_accuracy: 0.8190\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2729 - accuracy: 0.8895 - val_loss: 0.5178 - val_accuracy: 0.8080\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2626 - accuracy: 0.8946 - val_loss: 0.4686 - val_accuracy: 0.8130\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2667 - accuracy: 0.8902 - val_loss: 0.4635 - val_accuracy: 0.8240\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2642 - accuracy: 0.8888 - val_loss: 0.4717 - val_accuracy: 0.8260\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2629 - accuracy: 0.8921 - val_loss: 0.4724 - val_accuracy: 0.8290\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2647 - accuracy: 0.8919 - val_loss: 0.4651 - val_accuracy: 0.8190\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2537 - accuracy: 0.8966 - val_loss: 0.4971 - val_accuracy: 0.8180\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2565 - accuracy: 0.8932 - val_loss: 0.4784 - val_accuracy: 0.8180\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2543 - accuracy: 0.8966 - val_loss: 0.4818 - val_accuracy: 0.8110\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2503 - accuracy: 0.8979 - val_loss: 0.4996 - val_accuracy: 0.8110\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2555 - accuracy: 0.9000 - val_loss: 0.5243 - val_accuracy: 0.8110\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2467 - accuracy: 0.8987 - val_loss: 0.5021 - val_accuracy: 0.8230\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2571 - accuracy: 0.8962 - val_loss: 0.5159 - val_accuracy: 0.8080\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2519 - accuracy: 0.8996 - val_loss: 0.4902 - val_accuracy: 0.8150\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2509 - accuracy: 0.8984 - val_loss: 0.4795 - val_accuracy: 0.8200\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2505 - accuracy: 0.8996 - val_loss: 0.5097 - val_accuracy: 0.8190\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2446 - accuracy: 0.8998 - val_loss: 0.5370 - val_accuracy: 0.8080\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2519 - accuracy: 0.8992 - val_loss: 0.5175 - val_accuracy: 0.8120\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2411 - accuracy: 0.9006 - val_loss: 0.4924 - val_accuracy: 0.8260\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2410 - accuracy: 0.9027 - val_loss: 0.5185 - val_accuracy: 0.8110\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2413 - accuracy: 0.9059 - val_loss: 0.5552 - val_accuracy: 0.8190\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2404 - accuracy: 0.9029 - val_loss: 0.5235 - val_accuracy: 0.8180\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2389 - accuracy: 0.9019 - val_loss: 0.5583 - val_accuracy: 0.8140\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2329 - accuracy: 0.9074 - val_loss: 0.5083 - val_accuracy: 0.8130\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2413 - accuracy: 0.9029 - val_loss: 0.5479 - val_accuracy: 0.8080\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTbld8PufEqv"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwZGRe3gfEqv",
        "outputId": "a01266d8-1e30-4a84-d01f-8f4c3d31f2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ],
      "source": [
        "filename = 'ChatBot_Model.h5'\n",
        "model.save(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z43ZXSzsfEqv"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "### Training Accuracy plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "rdXnrTuQfEqv",
        "outputId": "5f2b9996-4add-4c1a-c51f-ae0266996d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxEKQZ0fEqw"
      },
      "source": [
        "### Evaluating on Given Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vyPA6KoPfEqw"
      },
      "outputs": [],
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W738nJcfEqw",
        "outputId": "89e66c81-e519-4e6e-dfe2-49a5baf40f1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS0FLlgYfEqw",
        "outputId": "14542b4b-528d-479a-8c09-b4d62843b534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ]
        }
      ],
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Pvfg3ffEqw",
        "outputId": "a784a65f-fc9a-4b05-c295-1a2039776eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ],
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zwj0HwzfEqw",
        "outputId": "4cae8756-6759-4dcb-cf22-bad62eba77d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Test Answer from Data is: no\n"
          ]
        }
      ],
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFlROEGFfEqx",
        "outputId": "2dc266a3-bc40-4698-e0f7-3a794da9e153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9999999\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcR-VaxcfEqx"
      },
      "source": [
        "## Testing with our own Stories and Questions\n",
        "\n",
        "Picking out words from the existing vocabulary - "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7Vf6Nv1fEqx",
        "outputId": "ddaf10e4-c4be-4ab2-feb3-2847c00744ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDIlXDzkfEqx",
        "outputId": "1afe2ca8-6859-415d-8336-44bc9d1772d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RMR3JLawfEqx"
      },
      "outputs": [],
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12rhjxELfEqy",
        "outputId": "86ad2ed9-d5e9-4cae-b51f-2d7b900163b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_question.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "veOPRH9cfEqy"
      },
      "outputs": [],
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qNFuPcn7fEqy"
      },
      "outputs": [],
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WR7NFsF6fEqy"
      },
      "outputs": [],
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TyiUQVpfEqy",
        "outputId": "629d5b83-c021-4f89-e2a3-c1d50c9ff683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.97079676\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "ChatBot_Model.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}